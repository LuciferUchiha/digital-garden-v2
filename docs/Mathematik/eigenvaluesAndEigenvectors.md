---
title: Eigenvalues And Eigenvectors
tags: [vectors, matrices, linear algebra]
---


<!--- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! Instead, edit the notebook w/the location & name as this file.-->

Before we talk about eigenvalues and eigenvectors let us just remind ourselves that vectors can be transformed using matrices. For example we can rotate a vector using the rotation matrix:

![2dRotationMatrix](/img/maths/2dRotationMatrix.png)

$$
\begin{bmatrix}
  \cos\theta & -\sin\theta \\
  \sin\theta &  \cos\theta \\
\end{bmatrix}\begin{bmatrix}
  x \\
  y \\
\end{bmatrix}
=
\begin{bmatrix}
  x' \\
  y' \\
\end{bmatrix}
$$

Or we can use a matrix to scale a vector:

![scalingVector](/img/maths/scalingVector.png)

$$
\begin{bmatrix}
  10 & 0 \\
  0 & 10 \\
\end{bmatrix}\begin{bmatrix}
  5 \\
  10 \\
\end{bmatrix}
=
\begin{bmatrix}
  50 \\
  100 \\
\end{bmatrix}
$$

Now let us go back to eigenvalues and eigenvectors. An eigenvector $\bm{v}$ of a square matrix $\bm{A}$ is defined as a non-zero vector such that the multiplication with $\bm{A}$ only changes the scale of the vector it does not change the direction. The scalar $\lambda$ is called the eigenvalue.

$$\bm{Av}=\lambda \bm{v}$$

Because there would be an infinite amount of solutions we limit the magnitude of the vector to $\parallel\bm{v}\parallel_2=1$.

Let us look at an example of how to calculate the eigenvector and eigenvalue of

$$
\bm{A}=
\begin{bmatrix}
  0 & 1 \\
  -2 & -3 \\
\end{bmatrix}
$$

For this we can rewrite the problem and solve the following equations:

$$
\begin{align*}
\bm{Av}=\lambda \bm{v} \\
\bm{Av} - \lambda \bm{v} = 0 \\
\bm{Av} - \lambda \bm{Iv} = 0
(\bm{A} - \lambda \bm{I})\bm{v} = 0
\end{align*}
$$

For there to be a solution where $\bm{v}$ is non-zero then the following must be true and which then must lead to the characteristic polynomial of $\bm{A}$. Solving the characteristic polynomial equaling 0 we can get between 0 and $n$ eigenvalues with $n$ being the number of dimensions of $\bm{A} \in \mathbb{R}^{n \times n}$:

$$
\begin{align*}
det(\bm{A}-\lambda\bm{I}) &= 0 \\
det\big(
    \begin{bmatrix}
      0 & 1 \\
      -2 & -3 \\
    \end{bmatrix}
    - \begin{bmatrix}
      \lambda & 0 \\
      0 & \lambda \\
    \end{bmatrix}
\big) &= 0 \\
det\big(
    \begin{bmatrix}
      -\lambda & 1 \\
      -2 & -3-\lambda \\
    \end{bmatrix}
\big) &= \lambda^2+3\lambda+2=0 \\
&\lambda_1 = -1,\,\lambda_2 = -2
\end{align*}
$$

Now that we have the eigenvalues all we need to do is calculate the eigenvectors corresponding to each eigenvalue.

$$
\begin{align*}
(\bm{A} - \lambda \bm{I})\bm{v} &= 0 \\
\big(\begin{bmatrix}
      0 & 1 \\
      -2 & -3 \\
\end{bmatrix}
- \begin{bmatrix}
      -1 & 0 \\
      0 & -1 \\
\end{bmatrix} \big)
\begin{bmatrix}
      v_1 \\
      v_2 \\
\end{bmatrix} &= 0 \\
\begin{bmatrix}
      1 & 1 \\
      -2 & -2 \\
\end{bmatrix}
\begin{bmatrix}
      v_1 \\
      v_2 \\
\end{bmatrix} &= 0 \\
\begin{bmatrix}
      v_1 + v_2 \\
      -2v_1 -2v_2 \\
\end{bmatrix} &= 0 \\
&\Rightarrow v_1 = -v_2
\end{align*}
$$

So we know $v_1 = -v_2$ since we constrict ourselves to vectors with a magnitude of 1 so $\sqrt{v_1^2 + (-v_1)^2}=1$ we get for eigenvalue $\lambda_1=-1$ the eigenvector
$$\bm{v}=\begin{bmatrix}
      0.707107 \\
      -0.707107 \\
\end{bmatrix}$$

We can also calculate this using the following numpy code:


```python
import numpy as np
A = np.array([[0, 1], [-2, -3]])
w, v = np.linalg.eig(A)
print(f"Eigenvalues: {w}")
print(f"Eigenvectors: {v}")
```

<CodeOutputBlock lang="python">

    Eigenvalues: [-1. -2.]
    Eigenvectors: [[ 0.70710678 -0.4472136 ]
     [-0.70710678  0.89442719]]


</CodeOutputBlock>

## Properties

We can use the eigenvalues and eigenvectors of the matrix $\bm{A}$ to find out a lot about it

- The trace of $\bm{A}$ is the sum of its eigenvalues $tr(\bm{A})=\sum_{i=1}^{n}{\lambda_i}$.
- The determinant of $\bm{A}$ is the product of its eigenvalues $tr(\bm{A})=\prod_{i=1}^{n}{\lambda_i}$.
- The rank of $\bm{A}$ is amount of non-zero eigenvalues.



```python
print(f"Trace: {np.trace(A)}")
print(f"Determinant: {np.linalg.det(A)}")
print(f"Rank: {np.linalg.matrix_rank(A)}")
```

<CodeOutputBlock lang="python">

    Trace: -3
    Determinant: 2.0
    Rank: 2


</CodeOutputBlock>

If $\bm{A}$ is a diagonal matrix then the eigenvalues are just the diagonal elements.


```python
D = np.diag([1,2,3])
w, v = np.linalg.eig(D)
print(f"Eigenvalues: {w}")
print(f"Eigenvectors: {v}")
```

<CodeOutputBlock lang="python">

    Eigenvalues: [1. 2. 3.]
    Eigenvectors: [[1. 0. 0.]
     [0. 1. 0.]
     [0. 0. 1.]]


</CodeOutputBlock>

## Eigendecomposition

